{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "504e48df-1c9c-4d1e-83e9-681d52f20427",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "enc = tiktoken.get_encoding(\"o200k_base\")\n",
    "assert enc.decode(enc.encode(\"hello world\")) == \"hello world\"\n",
    "\n",
    "# To get the tokeniser corresponding to a specific model in the OpenAI API:\n",
    "enc = tiktoken.encoding_for_model(\"gpt-4o\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9788da35-a74d-4757-afda-32e20d352dcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "enc = tiktoken.encoding_for_model(\"gpt-5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c576fbd2-ba14-436e-8d11-46c0f6ca852a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[31mType:\u001b[39m           Encoding\n",
       "\u001b[31mString form:\u001b[39m    <Encoding 'o200k_base'>\n",
       "\u001b[31mFile:\u001b[39m           ~/anaconda3/envs/arena-env/lib/python3.11/site-packages/tiktoken/core.py\n",
       "\u001b[31mDocstring:\u001b[39m      <no docstring>\n",
       "\u001b[31mInit docstring:\u001b[39m\n",
       "Creates an Encoding object.\n",
       "\n",
       "See openai_public.py for examples of how to construct an Encoding object.\n",
       "\n",
       "Args:\n",
       "    name: The name of the encoding. It should be clear from the name of the encoding\n",
       "        what behaviour to expect, in particular, encodings with different special tokens\n",
       "        should have different names.\n",
       "    pat_str: A regex pattern string that is used to split the input text.\n",
       "    mergeable_ranks: A dictionary mapping mergeable token bytes to their ranks. The ranks\n",
       "        must correspond to merge priority.\n",
       "    special_tokens: A dictionary mapping special token strings to their token values.\n",
       "    explicit_n_vocab: The number of tokens in the vocabulary. If provided, it is checked\n",
       "        that the number of mergeable tokens and special tokens is equal to this number."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "enc?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "85eb6ff9-78f2-4aae-855b-5f01655a8869",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 !\n",
      "1 \"\n",
      "2 #\n",
      "3 $\n",
      "4 %\n",
      "5 &\n",
      "6 '\n",
      "7 (\n",
      "8 )\n",
      "9 *\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    print(i, enc.decode([i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8c9108c4-f527-4af5-84d2-22eb664dfb0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000  القد\n",
      "50001 urin\n",
      "50002 _pattern\n",
      "50003  headquarters\n",
      "50004  оказ\n",
      "50005 ‑\n",
      "50006  специалист\n",
      "50007 下午\n",
      "50008 иф\n",
      "50009  MR\n",
      "50010 Backup\n",
      "50011  mogen\n",
      "50012 .il\n",
      "50013  cleans\n",
      "50014  Terra\n",
      "50015  lemma\n",
      "50016 837\n",
      "50017 (range\n",
      "50018 ​ស\n",
      "50019 mass\n",
      "50020  彩神争霸是\n",
      "50021 Так\n",
      "50022 ुद्ध\n",
      "50023  newspapers\n",
      "50024 ريف\n",
      "50025 анг\n",
      "50026 idwa\n",
      "50027  nadie\n",
      "50028 ుడ\n",
      "50029  Poland\n",
      "50030  [\n",
      "\n",
      "50031 �ევ\n",
      "50032 」「\n",
      "50033  sampeyan\n",
      "50034  acad\n",
      "50035  película\n",
      "50036 863\n",
      "50037  conflicts\n",
      "50038  bestimm\n",
      "50039  vocabulary\n",
      "50040  bụrụ\n",
      "50041 ilh\n",
      "50042  consulta\n",
      "50043  μου\n",
      "50044  मात्र\n",
      "50045  amat\n",
      "50046  clay\n",
      "50047  Ign\n",
      "50048 foto\n",
      "50049 \"'\n"
     ]
    }
   ],
   "source": [
    "for i in range(50000, 50050):\n",
    "    print(i, enc.decode([i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3ca51711-1349-4330-9db2-4db0a6aabd74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199990 ):(\n",
      "199991  Produit\n",
      "199992 Aircraft\n",
      "199993 iffen\n",
      "199994  patrones\n",
      "199995  parâmetros\n",
      "199996 Cursos\n",
      "199997  cocos\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'Invalid token for decoding: 199998'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[20]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[32m199990\u001b[39m, \u001b[32m200010\u001b[39m):\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m     \u001b[38;5;28mprint\u001b[39m(i, \u001b[43menc\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/arena-env/lib/python3.11/site-packages/tiktoken/core.py:284\u001b[39m, in \u001b[36mEncoding.decode\u001b[39m\u001b[34m(self, tokens, errors)\u001b[39m\n\u001b[32m    272\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdecode\u001b[39m(\u001b[38;5;28mself\u001b[39m, tokens: Sequence[\u001b[38;5;28mint\u001b[39m], errors: \u001b[38;5;28mstr\u001b[39m = \u001b[33m\"\u001b[39m\u001b[33mreplace\u001b[39m\u001b[33m\"\u001b[39m) -> \u001b[38;5;28mstr\u001b[39m:\n\u001b[32m    273\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Decodes a list of tokens into a string.\u001b[39;00m\n\u001b[32m    274\u001b[39m \n\u001b[32m    275\u001b[39m \u001b[33;03m    WARNING: the default behaviour of this function is lossy, since decoded bytes are not\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    282\u001b[39m \u001b[33;03m    ```\u001b[39;00m\n\u001b[32m    283\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m284\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._core_bpe.decode_bytes(tokens).decode(\u001b[33m\"\u001b[39m\u001b[33mutf-8\u001b[39m\u001b[33m\"\u001b[39m, errors=errors)\n",
      "\u001b[31mKeyError\u001b[39m: 'Invalid token for decoding: 199998'"
     ]
    }
   ],
   "source": [
    "for i in range(199990, 200010):\n",
    "    print(i, enc.decode([i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ff58680-0183-4cd0-83a9-3fcb8888d628",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
