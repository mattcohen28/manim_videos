{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0c7ca14c-83b1-42a3-a5a3-06713a61b7a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn import functional as F\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d36780fd-1e61-416c-9c3d-a1609b884e42",
   "metadata": {},
   "outputs": [],
   "source": [
    "device='cuda'\n",
    "model_id = \"meta-llama/Llama-3.2-1B\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2345faa3-a0b5-4f7a-9f22-56fc210f4247",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(model_id).to(device)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "model.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2c9662bf-f24c-4ffe-868d-f853ec7599d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"The capital of France is\"\n",
    "inputs = tokenizer(text, return_tensors=\"pt\").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1816e7c7-5a34-479d-b42c-1b67a5acddbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128000 <|begin_of_text|>\n",
      "791 The\n",
      "6864  capital\n",
      "315  of\n",
      "9822  France\n",
      "374  is\n"
     ]
    }
   ],
   "source": [
    "#Tokenizer prepends a speical <|begin_of_text|> token\n",
    "for input_token_index in inputs['input_ids'].view(-1):\n",
    "    print(input_token_index.item(), tokenizer.decode(input_token_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "74fce40d-bfd6-49f9-90d7-3978a60dfee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pass inputs into model\n",
    "with torch.no_grad():\n",
    "    outputs=model(inputs[\"input_ids\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cdadbf2e-3359-4235-8014-a901d3bece70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 6, 128256])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#One output vector for each input token, each vector has one value for each token in Llama's 128256 token vocabulary\n",
    "outputs.logits.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "76487093-9f3e-44f9-9276-f1bb13ee89a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 6, 128256])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probabilities=F.softmax(outputs.logits, dim=-1) #Convert to probabilities (more on this in Ch. 3)\n",
    "probabilities.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d71f7a59-b0bc-422f-8737-bd7659e8705d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12366 0.39153  Paris\n",
      "264 0.08419  a\n",
      "279 0.07039  the\n",
      "832 0.03096  one\n",
      "1101 0.03061  also\n",
      "2162 0.02528  home\n",
      "3967 0.02462  known\n",
      "539 0.01659  not\n",
      "459 0.01241  an\n",
      "7559 0.01172  located\n"
     ]
    }
   ],
   "source": [
    "#Just look at final vector to see what text the model predicts next\n",
    "top_probs, top_indices = torch.topk(probabilities[0, -1, :], 10)\n",
    "for i, (prob, idx) in enumerate(zip(top_probs, top_indices), 1):\n",
    "    print(idx.item(), round(probabilities[0, -1, idx].item(),5), tokenizer.decode([idx]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c5b64e8b-fc72-4ccf-bbb0-7b562a893b3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode([0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0a066c14-173d-44fe-8916-e8ecdb446510",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\"'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode([1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e06d17d0-2ef4-4f89-9828-f11e7591f6f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<|reserved_special_token_247|>'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode([128255])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9d13ce88-37cc-455d-8753-ec5d745e8b7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<|reserved_special_token_246|>'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode([128254])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa940b07-7f97-4879-a709-35f0e1d3b78c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
